{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051747,
     "end_time": "2021-03-26T05:39:21.829565",
     "exception": false,
     "start_time": "2021-03-26T05:39:21.777818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059844,
     "end_time": "2021-03-26T05:39:22.045947",
     "exception": false,
     "start_time": "2021-03-26T05:39:21.986103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Idea behind finding genuine reviews from data sets:\n",
    "\n",
    "> Part 1: Prediction of Helpfulness from given data i.e if people found review helpful or not.\n",
    "\n",
    "> Part 2: Classification of genuine and fake/sarcastic reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045698,
     "end_time": "2021-03-26T05:39:22.148281",
     "exception": false,
     "start_time": "2021-03-26T05:39:22.102583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data Preparation\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047418,
     "end_time": "2021-03-26T05:39:22.241674",
     "exception": false,
     "start_time": "2021-03-26T05:39:22.194256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data preprocessing for \"Preparing data\" for the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-26T05:39:22.349873Z",
     "iopub.status.busy": "2021-03-26T05:39:22.349062Z",
     "iopub.status.idle": "2021-03-26T05:39:24.987294Z",
     "shell.execute_reply": "2021-03-26T05:39:24.985828Z"
    },
    "papermill": {
     "duration": 2.694177,
     "end_time": "2021-03-26T05:39:24.987635",
     "exception": false,
     "start_time": "2021-03-26T05:39:22.293458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the required files.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import string\n",
    "from time import time\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "stops = set(stopwords.words(\"english\"))\n",
    "import re\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "RAN_STATE = 42 # Setting the random state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048078,
     "end_time": "2021-03-26T05:39:25.316449",
     "exception": false,
     "start_time": "2021-03-26T05:39:25.268371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, reading of the data.\n",
    "\n",
    "The dataset is a JSON file -> use the-> read_json() function of Pandas.\n",
    "Use *lines=True*  to read the file as a JSON object per line or else it will show an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content of dataset -\n",
    "* 5-core dataset of product reviews from Amazon Electronics category from May 1996 - July 2014. \n",
    "* Contains total of 1689188 entries. \n",
    "* Each reviewer has at least 5 reviews and each product has at least 5 reviews in this dataset.\n",
    "\n",
    "Columns are:\n",
    "* asin (Amazon Standard Identification Number)- ID of the product, like B000FA64PK (basically a aplhanumeric number for product identification)\n",
    "* helpful - helpfulness rating of the review - example: 2/3.\n",
    "* overall - rating of the product.\n",
    "* reviewText - text of the review (heading).\n",
    "* reviewTime - time of the review (raw).\n",
    "* reviewerID - ID of the reviewer, like A3SPTOKDG7WBLN\n",
    "* reviewerName - name of the reviewer.\n",
    "* summary - summary of the review (description).\n",
    "* unixReviewTime - unix timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T05:39:25.417838Z",
     "iopub.status.busy": "2021-03-26T05:39:25.417034Z",
     "iopub.status.idle": "2021-03-26T05:40:21.858977Z",
     "shell.execute_reply": "2021-03-26T05:40:21.859533Z"
    },
    "papermill": {
     "duration": 56.496351,
     "end_time": "2021-03-26T05:40:21.859730",
     "exception": false,
     "start_time": "2021-03-26T05:39:25.363379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>We got this GPS for my husband who is an (OTR)...</td>\n",
       "      <td>5</td>\n",
       "      <td>Gotta have GPS!</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[12, 15]</td>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>1</td>\n",
       "      <td>Very Disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>[43, 45]</td>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>3</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>[9, 10]</td>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2</td>\n",
       "      <td>Great grafics, POOR GPS</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1</td>\n",
       "      <td>Major issues, only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689183</th>\n",
       "      <td>A34BZM6S9L7QI4</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Candy Cane \"Is it just me?\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Burned these in before listening to them for a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Boom -- Pop -- Pow.  These deliver.</td>\n",
       "      <td>1405555200</td>\n",
       "      <td>07 17, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689184</th>\n",
       "      <td>A1G650TTTHEAL5</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Charles Spanky \"Zumina Reviews\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Some people like DJ style headphones or earbud...</td>\n",
       "      <td>5</td>\n",
       "      <td>Thin and light, without compromising on sound ...</td>\n",
       "      <td>1405382400</td>\n",
       "      <td>07 15, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689185</th>\n",
       "      <td>A25C2M3QF9G7OQ</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Comdet</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I&amp;#8217;m a big fan of the Brainwavz S1 (actua...</td>\n",
       "      <td>5</td>\n",
       "      <td>Same form factor and durability as the S1 with...</td>\n",
       "      <td>1405555200</td>\n",
       "      <td>07 17, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689186</th>\n",
       "      <td>A1E1LEVQ9VQNK</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>J. Chambers</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I've used theBrainwavz S1 In Ear Headphones, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>Superb audio quality in a very comfortable set...</td>\n",
       "      <td>1405641600</td>\n",
       "      <td>07 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689187</th>\n",
       "      <td>A2NYK9KWFMJV4Y</td>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>Mike Tarrani \"Jazz Drummer\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Normally when I receive a review sample I can ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Exceptional sound</td>\n",
       "      <td>1405209600</td>\n",
       "      <td>07 13, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1689188 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID        asin                     reviewerName  \\\n",
       "0         AO94DHGC771SJ  0528881469                          amazdnu   \n",
       "1         AMO214LNFCEI4  0528881469                  Amazon Customer   \n",
       "2        A3N7T0DY83Y4IG  0528881469                    C. A. Freeman   \n",
       "3        A1H8PY3QHMQQA0  0528881469         Dave M. Shaw \"mack dave\"   \n",
       "4        A24EV6RXELQZ63  0528881469                      Wayne Smith   \n",
       "...                 ...         ...                              ...   \n",
       "1689183  A34BZM6S9L7QI4  B00LGQ6HL8      Candy Cane \"Is it just me?\"   \n",
       "1689184  A1G650TTTHEAL5  B00LGQ6HL8  Charles Spanky \"Zumina Reviews\"   \n",
       "1689185  A25C2M3QF9G7OQ  B00LGQ6HL8                           Comdet   \n",
       "1689186   A1E1LEVQ9VQNK  B00LGQ6HL8                      J. Chambers   \n",
       "1689187  A2NYK9KWFMJV4Y  B00LGQ6HL8      Mike Tarrani \"Jazz Drummer\"   \n",
       "\n",
       "          helpful                                         reviewText  overall  \\\n",
       "0          [0, 0]  We got this GPS for my husband who is an (OTR)...        5   \n",
       "1        [12, 15]  I'm a professional OTR truck driver, and I bou...        1   \n",
       "2        [43, 45]  Well, what can I say.  I've had this unit in m...        3   \n",
       "3         [9, 10]  Not going to write a long review, even thought...        2   \n",
       "4          [0, 0]  I've had mine for a year and here's what we go...        1   \n",
       "...           ...                                                ...      ...   \n",
       "1689183    [1, 1]  Burned these in before listening to them for a...        5   \n",
       "1689184    [0, 0]  Some people like DJ style headphones or earbud...        5   \n",
       "1689185    [0, 0]  I&#8217;m a big fan of the Brainwavz S1 (actua...        5   \n",
       "1689186    [0, 0]  I've used theBrainwavz S1 In Ear Headphones, a...        5   \n",
       "1689187    [0, 0]  Normally when I receive a review sample I can ...        5   \n",
       "\n",
       "                                                   summary  unixReviewTime  \\\n",
       "0                                          Gotta have GPS!      1370131200   \n",
       "1                                        Very Disappointed      1290643200   \n",
       "2                                           1st impression      1283990400   \n",
       "3                                  Great grafics, POOR GPS      1290556800   \n",
       "4                   Major issues, only excuses for support      1317254400   \n",
       "...                                                    ...             ...   \n",
       "1689183                Boom -- Pop -- Pow.  These deliver.      1405555200   \n",
       "1689184  Thin and light, without compromising on sound ...      1405382400   \n",
       "1689185  Same form factor and durability as the S1 with...      1405555200   \n",
       "1689186  Superb audio quality in a very comfortable set...      1405641600   \n",
       "1689187                                  Exceptional sound      1405209600   \n",
       "\n",
       "          reviewTime  \n",
       "0         06 2, 2013  \n",
       "1        11 25, 2010  \n",
       "2         09 9, 2010  \n",
       "3        11 24, 2010  \n",
       "4        09 29, 2011  \n",
       "...              ...  \n",
       "1689183  07 17, 2014  \n",
       "1689184  07 15, 2014  \n",
       "1689185  07 17, 2014  \n",
       "1689186  07 18, 2014  \n",
       "1689187  07 13, 2014  \n",
       "\n",
       "[1689188 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read json data\n",
    "data=pd.read_json('Review_Set5.json',lines=True,orient='columns')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045485,
     "end_time": "2021-03-26T05:40:21.953038",
     "exception": false,
     "start_time": "2021-03-26T05:40:21.907553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "using the drop_duplicate() function to remove duplicates of reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T05:40:22.186540Z",
     "iopub.status.busy": "2021-03-26T05:40:22.185786Z",
     "iopub.status.idle": "2021-03-26T05:40:27.723475Z",
     "shell.execute_reply": "2021-03-26T05:40:27.721990Z"
    },
    "papermill": {
     "duration": 5.723417,
     "end_time": "2021-03-26T05:40:27.723764",
     "exception": false,
     "start_time": "2021-03-26T05:40:22.000347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data set before removing duplicate reviews : (1689188, 9)\n",
      "The shape of the data set after removing duplicate reviews : (1687169, 9)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate reviews(if any)\n",
    "print(\"The shape of the data set before removing duplicate reviews : {}\".format(data.shape))\n",
    "data=data.drop_duplicates(subset=[\"reviewText\"], keep='first', inplace=False)\n",
    "print(\"The shape of the data set after removing duplicate reviews : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048789,
     "end_time": "2021-03-26T05:40:27.829736",
     "exception": false,
     "start_time": "2021-03-26T05:40:27.780947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "duplicate reviews removed. \n",
    "Now, time for text preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060829,
     "end_time": "2021-03-26T05:40:27.938984",
     "exception": false,
     "start_time": "2021-03-26T05:40:27.878155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Text Preprocessing\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056199,
     "end_time": "2021-03-26T05:40:28.056506",
     "exception": false,
     "start_time": "2021-03-26T05:40:28.000307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to preprocess the data because the same preprocessed data will be needed for step 1 and 2\n",
    "\n",
    "Preprocessing the whole data took approximately an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T05:40:28.164788Z",
     "iopub.status.busy": "2021-03-26T05:40:28.163654Z",
     "iopub.status.idle": "2021-03-26T05:40:28.167090Z",
     "shell.execute_reply": "2021-03-26T05:40:28.166579Z"
    },
    "papermill": {
     "duration": 0.062218,
     "end_time": "2021-03-26T05:40:28.167241",
     "exception": false,
     "start_time": "2021-03-26T05:40:28.105023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = x.replace(\",000,000\", \" m\").replace(\",000\", \" k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \" will not\").replace(\"cannot\", \" can not\").replace(\"can't\", \" can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \" what is\").replace(\"it's\", \" it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"'m\", \" am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \" he is\").replace(\"she's\", \" she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\").replace(\"how's\",\" how has\").replace(\"y'all\",\" you all\")\\\n",
    "                           .replace(\"o'clock\",\" of the clock\").replace(\"ne'er\",\" never\").replace(\"let's\",\" let us\")\\\n",
    "                           .replace(\"finna\",\" fixing to\").replace(\"gonna\",\" going to\").replace(\"gimme\",\" give me\").replace(\"gotta\",\" got to\").replace(\"'d\",\" would\")\\\n",
    "                           .replace(\"daresn't\",\" dare not\").replace(\"dasn't\",\" dare not\").replace(\"e'er\",\" ever\").replace(\"everyone's\",\" everyone is\")\\\n",
    "                           .replace(\"'cause'\",\" because\").replace(\"i'm\",\" i am\")\n",
    "    \n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    x=re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',x)\n",
    "    x=re.sub(r\"\\\\s*\\\\b(?=\\\\w*(\\\\w)\\\\1{2,})\\\\w*\\\\b\",' ',x)\n",
    "    x=re.sub(r'<.*?>',' ',x)\n",
    "    x=re.sub('[^a-zA-Z]',' ',x)\n",
    "    x=''.join([i for i in x if not i.isdigit()])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046572,
     "end_time": "2021-03-26T05:40:28.264872",
     "exception": false,
     "start_time": "2021-03-26T05:40:28.218300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, \n",
    "1. convert reviews to lowercase. \n",
    "2. Then we are going to do preprocessing. \n",
    "3. And finally, go to lemmatization.\n",
    "\n",
    "lemmatization over stemming is preferred because it extracts by considering vocabulary rather than just the root word in stemming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T05:40:28.372017Z",
     "iopub.status.busy": "2021-03-26T05:40:28.371269Z",
     "iopub.status.idle": "2021-03-26T06:17:32.324044Z",
     "shell.execute_reply": "2021-03-26T06:17:32.324692Z"
    },
    "papermill": {
     "duration": 2224.010722,
     "end_time": "2021-03-26T06:17:32.325051",
     "exception": false,
     "start_time": "2021-03-26T05:40:28.314329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "# Lower casing and removing punctuations\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data['reviewText'] = data['reviewText'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Removing stopwords\n",
    "#stop = stopwords.words('english')\n",
    "#data['reviewText'] = data['reviewText'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: preprocess(x))\n",
    "# Lemmatization\n",
    "\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data.reviewText.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049309,
     "end_time": "2021-03-26T06:17:32.426567",
     "exception": false,
     "start_time": "2021-03-26T06:17:32.377258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's start with Steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049534,
     "end_time": "2021-03-26T06:17:32.525926",
     "exception": false,
     "start_time": "2021-03-26T06:17:32.476392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050485,
     "end_time": "2021-03-26T06:17:32.727483",
     "exception": false,
     "start_time": "2021-03-26T06:17:32.676998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Idea behind this step\n",
    "--\n",
    "Amazon provides a system to rate the helpfulness of a review, but the problem with amazon is latest review is added at the top of the forum and despite of the rating it is not moved down or above.\n",
    "\n",
    "The Group goal is to create a model using machine learning techniques that would pre-rate the helpfulness of a given customer review before they are posted on the top of the forum. \n",
    "This way poor quality reviews would not be shown on top of forums.\n",
    "\n",
    "The model is trained on Amazon Reviews to predict if a given review is helpful or not helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049698,
     "end_time": "2021-03-26T06:17:32.826868",
     "exception": false,
     "start_time": "2021-03-26T06:17:32.777170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reading the data to check what we have at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:32.955919Z",
     "iopub.status.busy": "2021-03-26T06:17:32.954763Z",
     "iopub.status.idle": "2021-03-26T06:17:32.962967Z",
     "shell.execute_reply": "2021-03-26T06:17:32.963880Z"
    },
    "papermill": {
     "duration": 0.083237,
     "end_time": "2021-03-26T06:17:32.964498",
     "exception": false,
     "start_time": "2021-03-26T06:17:32.881261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050089,
     "end_time": "2021-03-26T06:17:33.067443",
     "exception": false,
     "start_time": "2021-03-26T06:17:33.017354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Targetted data columns:**\n",
    "> Input Features : reviewText,overall\n",
    "\n",
    "> Output labels: helpfulness\n",
    "\n",
    "**Reason for selecting input features:** When we give any review, along with text(reviewText) of the review we also give a rating in stars(overall).\n",
    "\n",
    "**the helpful column:** helpful column given above is a list containing two values---no of helpful ratings and the total no of ratings--- separated by a comma.\n",
    "\n",
    "We are dividing the helpful column into two parts i.e. \n",
    " \n",
    " > helpful_numerator => contains no. of helpful rating.\n",
    " \n",
    " > helpful_denominator => contains total no. of ratings.\n",
    "\n",
    "and then we are deleting the helpful column.\n",
    "Each column will have a single value data making it easier to operate on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:33.182752Z",
     "iopub.status.busy": "2021-03-26T06:17:33.182009Z",
     "iopub.status.idle": "2021-03-26T06:17:35.966208Z",
     "shell.execute_reply": "2021-03-26T06:17:35.965138Z"
    },
    "papermill": {
     "duration": 2.849211,
     "end_time": "2021-03-26T06:17:35.966454",
     "exception": false,
     "start_time": "2021-03-26T06:17:33.117243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#select the columns\n",
    "df = data.iloc[:, [5,4,3]]\n",
    "\n",
    "#split numerator and denominator\n",
    "df['helpful_numerator'] = df['helpful'].apply(lambda x: x[0])\n",
    "df['helpful_denominator'] = df['helpful'].apply(lambda x: x[1])\n",
    "\n",
    "# delete un-needed helpful column\n",
    "del df['helpful']\n",
    "\n",
    "#Check if we have any null values\n",
    "print (df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overall                0\n",
    "\n",
    "reviewText             0\n",
    "\n",
    "helpful_numerator      0\n",
    "\n",
    "helpful_denominator    0\n",
    "\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052237,
     "end_time": "2021-03-26T06:17:36.066982",
     "exception": false,
     "start_time": "2021-03-26T06:17:36.014745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "just a quick stats check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:36.178990Z",
     "iopub.status.busy": "2021-03-26T06:17:36.178014Z",
     "iopub.status.idle": "2021-03-26T06:17:36.367759Z",
     "shell.execute_reply": "2021-03-26T06:17:36.366929Z"
    },
    "papermill": {
     "duration": 0.252609,
     "end_time": "2021-03-26T06:17:36.368451",
     "exception": false,
     "start_time": "2021-03-26T06:17:36.115842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05185,
     "end_time": "2021-03-26T06:17:36.469779",
     "exception": false,
     "start_time": "2021-03-26T06:17:36.417929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, the dataset is huge(about 1687169 records), not all records are worth taking into consideration.\n",
    "So to narrow it down, take only those records that have at least 20 ratings in total.\n",
    "it is just based on the assumption that people can naturally spot the useless review and also our systems can't handle that much data for testing :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:36.586122Z",
     "iopub.status.busy": "2021-03-26T06:17:36.585395Z",
     "iopub.status.idle": "2021-03-26T06:17:36.610171Z",
     "shell.execute_reply": "2021-03-26T06:17:36.610717Z"
    },
    "papermill": {
     "duration": 0.086006,
     "end_time": "2021-03-26T06:17:36.610925",
     "exception": false,
     "start_time": "2021-03-26T06:17:36.524919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# include reviews that have more than 20 helpfulness data point only\n",
    "df1 = df[(df.helpful_denominator > 20)].copy()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051681,
     "end_time": "2021-03-26T06:17:36.713221",
     "exception": false,
     "start_time": "2021-03-26T06:17:36.661540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, to get our output label **helpfulness** which is the ratio of \n",
    "\n",
    "**helpfulness=helpful_numerator/helpful_denominator**.\n",
    "\n",
    "The result is compared with a threshold value(*let's keep threshold as 50%, but we can change it later per our requirement*).\n",
    "* If result > threshold ==> helpful = 1\n",
    "* if result < treshold ==> not helpful = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:36.822593Z",
     "iopub.status.busy": "2021-03-26T06:17:36.821708Z",
     "iopub.status.idle": "2021-03-26T06:17:36.843565Z",
     "shell.execute_reply": "2021-03-26T06:17:36.844097Z"
    },
    "papermill": {
     "duration": 0.080701,
     "end_time": "2021-03-26T06:17:36.844301",
     "exception": false,
     "start_time": "2021-03-26T06:17:36.763600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transform Helpfulness into a binary variable with 0.5 ratio\n",
    "threshold = 0.5s\n",
    "df1.loc[:, 'Helpful'] = np.where(df1.loc[:, 'helpful_numerator'] \\\n",
    "                                 / df1.loc[:, 'helpful_denominator'] > threshold, 1, 0)\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052406,
     "end_time": "2021-03-26T06:17:36.950528",
     "exception": false,
     "start_time": "2021-03-26T06:17:36.898122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, count the data to get total the distribution of helpfulness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:37.067575Z",
     "iopub.status.busy": "2021-03-26T06:17:37.066856Z",
     "iopub.status.idle": "2021-03-26T06:17:37.108289Z",
     "shell.execute_reply": "2021-03-26T06:17:37.107402Z"
    },
    "papermill": {
     "duration": 0.107305,
     "end_time": "2021-03-26T06:17:37.108488",
     "exception": false,
     "start_time": "2021-03-26T06:17:37.001183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check the balance\n",
    "print ('Count:')\n",
    "display(df1.groupby('Helpful').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052522,
     "end_time": "2021-03-26T06:17:37.215477",
     "exception": false,
     "start_time": "2021-03-26T06:17:37.162955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Final check on the data, since we are going to creating our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:37.344320Z",
     "iopub.status.busy": "2021-03-26T06:17:37.343262Z",
     "iopub.status.idle": "2021-03-26T06:17:37.352164Z",
     "shell.execute_reply": "2021-03-26T06:17:37.351379Z"
    },
    "papermill": {
     "duration": 0.083503,
     "end_time": "2021-03-26T06:17:37.352332",
     "exception": false,
     "start_time": "2021-03-26T06:17:37.268829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059183,
     "end_time": "2021-03-26T06:17:37.467222",
     "exception": false,
     "start_time": "2021-03-26T06:17:37.408039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We are ready with the dataset we need to operate on.\n",
    "Now, directly applying TF-IDF Vectorizer to generate more features.\n",
    "TF-IDF is an acronym of Term Frequency Inverse Document Frequency. It is a statistical measure used to find how important a word is to document in a collection or corpus. It is generally used in text mining and information retrieval.\n",
    "to operate on our review text data\n",
    "\n",
    "> TF: Term Frequency, which measures how frequently a term occurs in a document. \n",
    ">  \n",
    "> TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    ">  \n",
    "> IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important.:\n",
    ">  \n",
    "> IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:17:37.600112Z",
     "iopub.status.busy": "2021-03-26T06:17:37.594654Z",
     "iopub.status.idle": "2021-03-26T06:18:00.575496Z",
     "shell.execute_reply": "2021-03-26T06:18:00.576180Z"
    },
    "papermill": {
     "duration": 23.054653,
     "end_time": "2021-03-26T06:18:00.576401",
     "exception": false,
     "start_time": "2021-03-26T06:17:37.521748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# define the vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 0.01)\n",
    "# fit the vectorizers to the data.\n",
    "features = vectorizer.fit_transform(df1['reviewText'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05089,
     "end_time": "2021-03-26T06:18:00.681777",
     "exception": false,
     "start_time": "2021-03-26T06:18:00.630887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since we don't have a separate dataset for testing we are splitting data as 80% for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:18:00.794828Z",
     "iopub.status.busy": "2021-03-26T06:18:00.794064Z",
     "iopub.status.idle": "2021-03-26T06:18:00.844572Z",
     "shell.execute_reply": "2021-03-26T06:18:00.845189Z"
    },
    "papermill": {
     "duration": 0.109483,
     "end_time": "2021-03-26T06:18:00.845380",
     "exception": false,
     "start_time": "2021-03-26T06:18:00.735897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split and shuffle data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,df1['Helpful'], test_size=0.2, random_state=RAN_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052499,
     "end_time": "2021-03-26T06:18:00.954567",
     "exception": false,
     "start_time": "2021-03-26T06:18:00.902068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since our problem is of binary classification(helpful or not helpful), we are using roc_auc_score to evaluate our model.\n",
    "\n",
    "The roc_auc_score computes the area under the receiver operating characteristic (ROC) curve which is also denoted by AUC or AUROC. By computing the area under the roc curve, the curve information is summarized in one number.\n",
    "\n",
    "This curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR). The area under the curve is used to give a score to the model.\n",
    "> If AUC = 0.5 => TPR = FPR, and the model is doing just random computations.\n",
    ">\n",
    "> If AUC= 1.0 => TPR = 100%,and it is an ideal model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:18:01.073041Z",
     "iopub.status.busy": "2021-03-26T06:18:01.072169Z",
     "iopub.status.idle": "2021-03-26T06:18:01.076679Z",
     "shell.execute_reply": "2021-03-26T06:18:01.075880Z"
    },
    "papermill": {
     "duration": 0.069923,
     "end_time": "2021-03-26T06:18:01.076839",
     "exception": false,
     "start_time": "2021-03-26T06:18:01.006916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Print the results\n",
    "    print (\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on roc_auc score. '''\n",
    "    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    probas = clf.predict_proba(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Print and return results\n",
    "    print (\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    return roc_auc_score(target.values, probas[:,1].T)\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifer based on roc_auc score. '''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print (\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, X_train.shape[0]))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print (\"ROC_AUC score for training set: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print (\"ROC_AUC score for test set: {:.4f}.\\n\".format(predict_labels(clf, X_test, y_test)))\n",
    "    \n",
    "def clf_test_roc_score(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    probas = probas =clf.predict_proba(X_test)\n",
    "    return roc_auc_score(y_test, probas[:,1].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050646,
     "end_time": "2021-03-26T06:18:01.182153",
     "exception": false,
     "start_time": "2021-03-26T06:18:01.131507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To make a baseline model for our project we are going to use the following algorithms :\n",
    "\n",
    "* **GaussianNB**: \n",
    "<img src=\"https://imgur.com/nMRnwlL.png\" width=\"400px\">\n",
    "\n",
    "* **Logistic Regression**:\n",
    "* **Decision tree**: \n",
    "\n",
    "All the algorithms used here are popular algorithms for classification. However, since we are doing binary classification,\n",
    "Let's see which out of 3 gives better result: *Logistic Regression*, *Decision tree* or *Gaussian Naive Bayes*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:18:01.377284Z",
     "iopub.status.busy": "2021-03-26T06:18:01.376159Z",
     "iopub.status.idle": "2021-03-26T06:25:20.975310Z",
     "shell.execute_reply": "2021-03-26T06:25:20.974721Z"
    },
    "papermill": {
     "duration": 439.738957,
     "end_time": "2021-03-26T06:25:20.975491",
     "exception": false,
     "start_time": "2021-03-26T06:18:01.236534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the supervised learning models from sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Initialize the models using a random state were applicable.\n",
    "clf_list = [GaussianNB(),  \n",
    "            LogisticRegression(random_state = RAN_STATE),\n",
    "            DecisionTreeClassifier(random_state = RAN_STATE)]\n",
    "x_tr = X_train.toarray()\n",
    "x_te = X_test.toarray()\n",
    "\n",
    "\n",
    "# Set up the training set sizes for 10000, 20000 and 40000 respectively.\n",
    "train_feature_list = [x_tr[0:10000],x_tr[0:20000],x_tr]\n",
    "train_target_list = [y_train[0:10000], y_train[0:20000], y_train]\n",
    "\n",
    "\n",
    "# Execute the 'train_predict' function for each of the classifiers and each training set size\n",
    "for clf in clf_list:\n",
    "    for a, b in zip(train_feature_list, train_target_list):\n",
    "        train_predict(clf, a, b, x_te, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057812,
     "end_time": "2021-03-26T06:25:21.091789",
     "exception": false,
     "start_time": "2021-03-26T06:25:21.033977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It's a hassle to find each value. So let's just visualize the outputs for all models. Graphs make it's easier to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:25:21.218114Z",
     "iopub.status.busy": "2021-03-26T06:25:21.217460Z",
     "iopub.status.idle": "2021-03-26T06:32:37.813509Z",
     "shell.execute_reply": "2021-03-26T06:32:37.812913Z"
    },
    "papermill": {
     "duration": 436.663621,
     "end_time": "2021-03-26T06:32:37.813677",
     "exception": false,
     "start_time": "2021-03-26T06:25:21.150056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FIG_SIZE = (14,8)\n",
    "# Visualize all of the classifiers                                                               \n",
    "for clf in clf_list:\n",
    "    x_graph = []\n",
    "    y_graph = []\n",
    "    for a, b in zip(train_feature_list, train_target_list):\n",
    "        y_graph.append(clf_test_roc_score(clf, a, b, x_te, y_test))\n",
    "        x_graph.append(len(a))\n",
    "    plt.scatter(x_graph,y_graph)\n",
    "    plt.plot(x_graph,y_graph, label = clf.__class__.__name__)\n",
    "\n",
    "plt.title('Comparison of Different Classifiers')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('ROC_AUC score on test set')\n",
    "plt.legend(bbox_to_anchor=(1.6, 1.05))\n",
    "plt.figure(figsize=FIG_SIZE)             \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05838,
     "end_time": "2021-03-26T06:32:37.932911",
     "exception": false,
     "start_time": "2021-03-26T06:32:37.874531",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Logistic Regression gives us the best accuracy. \n",
    ">Its final score for the area under the ROC curve was 0.8704 and a sample size of ~40,000.\n",
    "\n",
    ">Besides, it is the fastest. The training speed and prediction speed were 19.993s and 0.955s  for a sample size of 40,000. \n",
    "\n",
    ">Since our model has to consider the accuracy and speed, the Logistic Regression algorithm represents the ideal model for us.\n",
    "\n",
    "Now, let's add values of scores to the review text and see if we can increase the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:32:38.082751Z",
     "iopub.status.busy": "2021-03-26T06:32:38.071025Z",
     "iopub.status.idle": "2021-03-26T06:32:38.678174Z",
     "shell.execute_reply": "2021-03-26T06:32:38.677395Z"
    },
    "papermill": {
     "duration": 0.682578,
     "end_time": "2021-03-26T06:32:38.678330",
     "exception": false,
     "start_time": "2021-03-26T06:32:37.995752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add Score column to features\n",
    "import scipy as scipy\n",
    "\n",
    "overall = np.array(list(df1.overall))\n",
    "overall = overall.reshape(features.shape[0], 1)\n",
    "\n",
    "features = scipy.sparse.hstack((features,scipy.sparse.csr_matrix(overall)))\n",
    "\n",
    "features = scipy.sparse.csr_matrix(features)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060039,
     "end_time": "2021-03-26T06:32:38.797441",
     "exception": false,
     "start_time": "2021-03-26T06:32:38.737402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can now split the dataset and try to optimize our initial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:32:38.924932Z",
     "iopub.status.busy": "2021-03-26T06:32:38.924195Z",
     "iopub.status.idle": "2021-03-26T06:32:38.969203Z",
     "shell.execute_reply": "2021-03-26T06:32:38.969897Z"
    },
    "papermill": {
     "duration": 0.113115,
     "end_time": "2021-03-26T06:32:38.970093",
     "exception": false,
     "start_time": "2021-03-26T06:32:38.856978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train, y_test = train_test_split(features, df1['Helpful'], test_size=0.2, random_state=RAN_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.06232,
     "end_time": "2021-03-26T06:32:39.092145",
     "exception": false,
     "start_time": "2021-03-26T06:32:39.029825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have used hyper-parameter, Hyper-parameters are parameters that are not directly learned within estimators. In scikit-learn, they are passed as arguments to the constructor of the estimator classes. Hyperparameter tuning helps us in optimizing our model.\n",
    "\n",
    "\n",
    "We will now be applying Gridsearch and Cross-Validation techniques to optimize and hypertune our model.\n",
    "\n",
    "* **GridSearch:** Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    "* **Cross-Validation:** In the train-test split, we use only 20% for testing. The performance metric we get on that 20% test data may not be accurate. So Cross-Validation allows you to consume 100% of the data for training and testing both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:32:39.225987Z",
     "iopub.status.busy": "2021-03-26T06:32:39.225288Z",
     "iopub.status.idle": "2021-03-26T06:35:09.525123Z",
     "shell.execute_reply": "2021-03-26T06:35:09.525923Z"
    },
    "papermill": {
     "duration": 150.371985,
     "end_time": "2021-03-26T06:35:09.526206",
     "exception": false,
     "start_time": "2021-03-26T06:32:39.154221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,cross_validate,StratifiedKFold\n",
    "#make the grid search object\n",
    "gs2 = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid={'C': [10**i for i in range(-5,5)], 'class_weight': [None, 'balanced']},\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "#fit the grid search object to our new dataset\n",
    "print ('Fitting grid search...')\n",
    "gs2.fit(X_train2, y_train)\n",
    "print (\"Grid search fitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063403,
     "end_time": "2021-03-26T06:35:09.654915",
     "exception": false,
     "start_time": "2021-03-26T06:35:09.591512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's the best estimator for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:09.789821Z",
     "iopub.status.busy": "2021-03-26T06:35:09.788966Z",
     "iopub.status.idle": "2021-03-26T06:35:09.794188Z",
     "shell.execute_reply": "2021-03-26T06:35:09.793395Z"
    },
    "papermill": {
     "duration": 0.074277,
     "end_time": "2021-03-26T06:35:09.794355",
     "exception": false,
     "start_time": "2021-03-26T06:35:09.720078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print the grid search scores.\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064395,
     "end_time": "2021-03-26T06:35:09.921117",
     "exception": false,
     "start_time": "2021-03-26T06:35:09.856722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see our optimized classifier is a LogisticRession with a 'C' parameter of 1 and a 'class_weight' = 'None'. This is the same as default, meaning our optimization step did not change the parameters of our model. Let's now find our ROC_AUC Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:10.057198Z",
     "iopub.status.busy": "2021-03-26T06:35:10.056024Z",
     "iopub.status.idle": "2021-03-26T06:35:10.073020Z",
     "shell.execute_reply": "2021-03-26T06:35:10.072028Z"
    },
    "papermill": {
     "duration": 0.084388,
     "end_time": "2021-03-26T06:35:10.073208",
     "exception": false,
     "start_time": "2021-03-26T06:35:09.988820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf2 = gs2.best_estimator_\n",
    "probas =clf2.predict_proba(X_test2)\n",
    "\n",
    "\n",
    "# ROC/AUC score\n",
    "print ('ROC_AUC Score:',roc_auc_score(y_test, probas[:,1].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068171,
     "end_time": "2021-03-26T06:35:10.210038",
     "exception": false,
     "start_time": "2021-03-26T06:35:10.141867",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wow! 90 % ROC_AUC Score. That means our model has been trained well.\n",
    "\n",
    "Let's now plot the graph to find the ROC Curve for Helpful Rating of both TFIDF and TFIDF along with the overall score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:10.352276Z",
     "iopub.status.busy": "2021-03-26T06:35:10.351063Z",
     "iopub.status.idle": "2021-03-26T06:35:12.967344Z",
     "shell.execute_reply": "2021-03-26T06:35:12.966762Z"
    },
    "papermill": {
     "duration": 2.692787,
     "end_time": "2021-03-26T06:35:12.967515",
     "exception": false,
     "start_time": "2021-03-26T06:35:10.274728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "probas = clf.predict_proba(X_test)\n",
    "clf2 = gs2.best_estimator_\n",
    "probas2 =clf2.predict_proba(X_test2)\n",
    "plt.figure(figsize = FIG_SIZE)\n",
    "\n",
    "# plot graph to show roc_auc_score.\n",
    "plt.plot(roc_curve(y_test, probas[:,1])[0], roc_curve(y_test, probas[:,1])[1], label = 'TFIDF')\n",
    "plt.plot(roc_curve(y_test, probas2[:,1])[0], roc_curve(y_test, probas2[:,1])[1], label = 'TFIDF + overall')\n",
    "plt.title('ROC Curve for Helpful Rating')\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.0, .5))\n",
    "plt.figure(figsize=FIG_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "LogisticRegression(random_state=0)\n",
    "plot_confusion_matrix(clf, X_test, y_test)  \n",
    "plt.show()\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "DecisionTreeClassifier(random_state=0)\n",
    "plot_confusion_matrix(clf, X_test, y_test)  \n",
    "plt.show()\n",
    "\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "plot_confusion_matrix(clf, X_test, y_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "LogisticRegression(random_state=0)\n",
    "LogisticRegression = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = LogisticRegression.predict(X_test)\n",
    "\n",
    "\n",
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "DecisionTreeClassifier(random_state=0)\n",
    "DecisionTreeClassifier = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "y_pred = DecisionTreeClassifier.predict(X_test)\n",
    "\n",
    "\n",
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')\n",
    "print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "GaussianNB = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = GaussianNB.predict(X_test)\n",
    "\n",
    "\n",
    "#importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)\n",
    "\n",
    "#importing accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('\\nClassification Report\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.066603,
     "end_time": "2021-03-26T06:35:13.100985",
     "exception": false,
     "start_time": "2021-03-26T06:35:13.034382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see in the above ROC Curve, adding an overall score to TFIDF vectors would give us a higher Area Under Curve(AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.070049,
     "end_time": "2021-03-26T06:35:13.235054",
     "exception": false,
     "start_time": "2021-03-26T06:35:13.165005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Conclusion:\n",
    "--\n",
    "The important quality of this step is the 'effect of introducing a new key feature to our model'.\n",
    "Here, we mainly looked at the TFIDF features generated from Amazon's Electronic Reviews text and added the 'overall_rating' (star rating) that was given to the product by the reviewer. \n",
    "We used these features to predict how 'helpful' other users would find the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068264,
     "end_time": "2021-03-26T06:35:13.372969",
     "exception": false,
     "start_time": "2021-03-26T06:35:13.304705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067433,
     "end_time": "2021-03-26T06:35:13.646007",
     "exception": false,
     "start_time": "2021-03-26T06:35:13.578574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thought Process behind this Step\n",
    "--\n",
    "The problem that is being addressed here is if Amazon Review is fake or not genuine. Sometimes some people give fake reviews on forums. This could harm the sale of the product if such a review came on top. \n",
    "\n",
    "**how we see fake review?**\n",
    "fake review: means a review which is given a 5-star rating but in review text, the person gives a negative review and since it is rated 5 stars, so chances are that review would come on top of the forum. \n",
    "\n",
    "Possibility exists that such reviews be given by competitors to harm the sale of the product.\n",
    "**Our solution to this:**\n",
    "Create a model using machine learning techniques that would classify given customer reviews based on sentiment analysis before they are posted on the top of the forum. This way fake reviews would not be shown on top of forums.\n",
    "\n",
    "The model will be trained on Amazon Reviews to classify if a given review is genuine or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.065219,
     "end_time": "2021-03-26T06:35:13.776034",
     "exception": false,
     "start_time": "2021-03-26T06:35:13.710815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's run a quick data check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:13.925858Z",
     "iopub.status.busy": "2021-03-26T06:35:13.925038Z",
     "iopub.status.idle": "2021-03-26T06:35:13.930739Z",
     "shell.execute_reply": "2021-03-26T06:35:13.930163Z"
    },
    "papermill": {
     "duration": 0.089067,
     "end_time": "2021-03-26T06:35:13.930910",
     "exception": false,
     "start_time": "2021-03-26T06:35:13.841843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.065732,
     "end_time": "2021-03-26T06:35:14.062327",
     "exception": false,
     "start_time": "2021-03-26T06:35:13.996595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here, we are going to select **reviewText** and **overall** score rating since we going to classify reviews based on these two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:14.207339Z",
     "iopub.status.busy": "2021-03-26T06:35:14.206599Z",
     "iopub.status.idle": "2021-03-26T06:35:14.712280Z",
     "shell.execute_reply": "2021-03-26T06:35:14.710619Z"
    },
    "papermill": {
     "duration": 0.581176,
     "end_time": "2021-03-26T06:35:14.712487",
     "exception": false,
     "start_time": "2021-03-26T06:35:14.131311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#select the columns\n",
    "df2 = data.iloc[:, [5,4]]\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067488,
     "end_time": "2021-03-26T06:35:14.850853",
     "exception": false,
     "start_time": "2021-03-26T06:35:14.783365",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How we classified the ratings as Positive, Negative, and Neutral.\n",
    "\n",
    "> * If the **score rating => 4 or 5**,we are taking it as **Positive**.\n",
    ">\n",
    "> * If the **score rating => 3**,we are taking it as **Neutral**.\n",
    ">\n",
    "> * And if the **score rating => 1 or 2**,we are taking it as **Negative**.\n",
    "\n",
    "Then we are saving the result in a column named **Overall_Sentiment**. This would tell us the sentiment of the review based on the star rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:14.990060Z",
     "iopub.status.busy": "2021-03-26T06:35:14.989076Z",
     "iopub.status.idle": "2021-03-26T06:35:36.450455Z",
     "shell.execute_reply": "2021-03-26T06:35:36.450979Z"
    },
    "papermill": {
     "duration": 21.535047,
     "end_time": "2021-03-26T06:35:36.451198",
     "exception": false,
     "start_time": "2021-03-26T06:35:14.916151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_classify(x):\n",
    "    if x>3:\n",
    "        return 'Positive'\n",
    "    elif x<3:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "df2['Overall_Sentiment']=df2.apply(lambda x: score_classify(x['overall']),axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.070312,
     "end_time": "2021-03-26T06:35:36.588837",
     "exception": false,
     "start_time": "2021-03-26T06:35:36.518525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's find out how the number of Positive, Negative, and Neutral reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:37.116522Z",
     "iopub.status.busy": "2021-03-26T06:35:37.115694Z",
     "iopub.status.idle": "2021-03-26T06:35:37.128264Z",
     "shell.execute_reply": "2021-03-26T06:35:37.127463Z"
    },
    "papermill": {
     "duration": 0.468663,
     "end_time": "2021-03-26T06:35:37.128467",
     "exception": false,
     "start_time": "2021-03-26T06:35:36.659804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.Overall_Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.06981,
     "end_time": "2021-03-26T06:35:37.265535",
     "exception": false,
     "start_time": "2021-03-26T06:35:37.195725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we can see that 1354351 reviews are Positive,190693 are Negative while 142125 are Neutral.\n",
    "\n",
    "But it may also be possible that some data may be missing or null. \n",
    "\n",
    "So we will now drop 'null values' if there are any. Then recheck the number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:37.698234Z",
     "iopub.status.busy": "2021-03-26T06:35:37.697204Z",
     "iopub.status.idle": "2021-03-26T06:35:38.540163Z",
     "shell.execute_reply": "2021-03-26T06:35:38.539370Z"
    },
    "papermill": {
     "duration": 1.204952,
     "end_time": "2021-03-26T06:35:38.540336",
     "exception": false,
     "start_time": "2021-03-26T06:35:37.335384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.dropna(\n",
    "    axis=0,\n",
    "    how='any',\n",
    "    thresh=None,\n",
    "    subset=None,\n",
    "    inplace=True\n",
    ")\n",
    "df2.Overall_Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069622,
     "end_time": "2021-03-26T06:35:38.682917",
     "exception": false,
     "start_time": "2021-03-26T06:35:38.613295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that there are no missing or null values.\n",
    "\n",
    "\n",
    "Now,it's time for sentiment analysis of review text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.071341,
     "end_time": "2021-03-26T06:35:38.823386",
     "exception": false,
     "start_time": "2021-03-26T06:35:38.752045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will use Sentiment analysis to computationally analyze and identify opinions and judgments of a customer from a piece of text.\n",
    "To understand if a piece of text is positive, negative, or neutral, based on their sentiment analysis.\n",
    "\n",
    "We are using aspect-based sentiment analysis here.\n",
    "\n",
    "Aspect-based sentiment analysis is generally for one or more aspects of a service or product. \n",
    "\n",
    "To a depth on how the customers feel about specific attributes of the product. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.084963,
     "end_time": "2021-03-26T06:35:38.977109",
     "exception": false,
     "start_time": "2021-03-26T06:35:38.892146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Aspect-based sentiment analysis can be implemented in different ways. \n",
    "\n",
    "We tried Sentiment Intensity Analyzer(commonly known as SIA) from vaderSentiment. \n",
    "\n",
    "But the found that sentiment from Textblob gives better results than SIA here. So we are stick to the sentiment from Textblob.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T06:35:39.222177Z",
     "iopub.status.busy": "2021-03-26T06:35:39.220865Z",
     "iopub.status.idle": "2021-03-26T07:03:30.110435Z",
     "shell.execute_reply": "2021-03-26T07:03:30.111302Z"
    },
    "papermill": {
     "duration": 1671.041805,
     "end_time": "2021-03-26T07:03:30.112113",
     "exception": false,
     "start_time": "2021-03-26T06:35:39.070308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentiment_score_list = []\n",
    "sentiment_label_list = []\n",
    "\n",
    "for i in df2['reviewText'].values.tolist():\n",
    "    sentiment_text=TextBlob(i)\n",
    "    sentiment_score = sentiment_text.sentiment.polarity\n",
    "    #print(sentiment_score)\n",
    "\n",
    "    if sentiment_score > 0:\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "        sentiment_label_list.append('Positive')\n",
    "    elif sentiment_score < 0:\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "        sentiment_label_list.append('Negative')\n",
    "    else:\n",
    "        sentiment_score_list.append(sentiment_score)\n",
    "        sentiment_label_list.append('Neutral')\n",
    "    \n",
    "df2['Review_Sentiment'] = sentiment_label_list\n",
    "df2['sentiment score'] = sentiment_score_list\n",
    "\n",
    "display(df2.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.071076,
     "end_time": "2021-03-26T07:03:30.258447",
     "exception": false,
     "start_time": "2021-03-26T07:03:30.187371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that some reviews are of Neutral, sentiment based on star rating bit are Positive, based on the sentiment of review text.\n",
    "\n",
    "Neutral reviews could be classified wrongly.\n",
    "\n",
    "So we are removing all Neutral reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T07:03:30.656642Z",
     "iopub.status.busy": "2021-03-26T07:03:30.407778Z",
     "iopub.status.idle": "2021-03-26T07:03:31.393499Z",
     "shell.execute_reply": "2021-03-26T07:03:31.392699Z"
    },
    "papermill": {
     "duration": 1.06475,
     "end_time": "2021-03-26T07:03:31.393679",
     "exception": false,
     "start_time": "2021-03-26T07:03:30.328929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "before=df2.shape[0]\n",
    "df2 = df2[df2.Overall_Sentiment != 'Neutral']\n",
    "df2 = df2[df2.Review_Sentiment != 'Neutral']\n",
    "df2.head(10)\n",
    "after=df2.shape[0]\n",
    "#EDA for finding how many neutral labels have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.073128,
     "end_time": "2021-03-26T07:03:31.542949",
     "exception": false,
     "start_time": "2021-03-26T07:03:31.469821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finding out how many Neutral reviews we have removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T07:03:31.702894Z",
     "iopub.status.busy": "2021-03-26T07:03:31.700834Z",
     "iopub.status.idle": "2021-03-26T07:03:31.709816Z",
     "shell.execute_reply": "2021-03-26T07:03:31.707399Z"
    },
    "papermill": {
     "duration": 0.092989,
     "end_time": "2021-03-26T07:03:31.710300",
     "exception": false,
     "start_time": "2021-03-26T07:03:31.617311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"The number of neutral labels have been removed : {}\".format(before-after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.070383,
     "end_time": "2021-03-26T07:03:31.852362",
     "exception": false,
     "start_time": "2021-03-26T07:03:31.781979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Significant amount of reviews have been removed.\n",
    "\n",
    "Now, let's classify reviews as true or false.\n",
    "\n",
    "**True review:** review in which the sentiment of star rating matches the sentiment of review text.\n",
    "\n",
    "**False review:** review in which the sentiment of star rating does not matches the sentiment of review text..\n",
    "Comparison done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T07:03:32.307741Z",
     "iopub.status.busy": "2021-03-26T07:03:32.305849Z",
     "iopub.status.idle": "2021-03-26T07:03:32.332650Z",
     "shell.execute_reply": "2021-03-26T07:03:32.333167Z"
    },
    "papermill": {
     "duration": 0.406297,
     "end_time": "2021-03-26T07:03:32.333436",
     "exception": false,
     "start_time": "2021-03-26T07:03:31.927139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comparison_column = np.where(df2[\"Overall_Sentiment\"] == df2[\"Review_Sentiment\"], True, False)\n",
    "df2[\"result\"] = comparison_column\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.073025,
     "end_time": "2021-03-26T07:03:32.484618",
     "exception": false,
     "start_time": "2021-03-26T07:03:32.411593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finding the total number of all the fake reviews. \n",
    "\n",
    "And running the data check on the fake review data-set we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-26T07:03:32.650056Z",
     "iopub.status.busy": "2021-03-26T07:03:32.649189Z",
     "iopub.status.idle": "2021-03-26T07:03:32.704323Z",
     "shell.execute_reply": "2021-03-26T07:03:32.703039Z"
    },
    "papermill": {
     "duration": 0.139905,
     "end_time": "2021-03-26T07:03:32.704601",
     "exception": false,
     "start_time": "2021-03-26T07:03:32.564696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df2[df2.result != True]\n",
    "print(df2.shape)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.077652,
     "end_time": "2021-03-26T07:03:32.857987",
     "exception": false,
     "start_time": "2021-03-26T07:03:32.780335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We found all the reviews that are not genuine and putting it figures it amounts to 202988 reviews.\n",
    "\n",
    ">That is a lot of reviews.\n",
    "\n",
    "\n",
    ">This part of the project is a SUCCESS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.077075,
     "end_time": "2021-03-26T07:03:33.011191",
     "exception": false,
     "start_time": "2021-03-26T07:03:32.934116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Successfully implemented:\n",
    "--\n",
    "> we can easily find out if the given review is genuine or not.\n",
    "\n",
    ">We used review text and star rating from Amazon's Reviews that was given to the product by the reviewer. \n",
    "\n",
    ">We used these features to classify if the given review is truly genuine or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5065.022717,
   "end_time": "2021-03-26T07:03:38.623664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-26T05:39:13.600947",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
